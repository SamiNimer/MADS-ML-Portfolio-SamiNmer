# Summary week 1
Lorem ipsum dolor sit amet, consectetur adipiscing elit.

Find the [notebook](./notebook.ipynb) and the [instructions](./instructions.md)

## First Run

At first, I ran the experiment without making any changes, just to get a sense of how everything works. Before executing the code, I took time to read through it carefully and tried to understand its structure and logic.

While reading, I encountered a question embedded in the code: "Why do you think I call it naive?" I believe the model is described as naive because it's relatively simple and hasn't been trained extensively. It uses a basic architecture and runs for only 3 epochs with 100 training steps. In my view, it's still in the early stages of learning—almost like it's guessing. That forms the basis of my null hypothesis: the model is naive due to its simplicity and limited training.

After visualizing the model, I’ll evaluate whether the evidence supports or refutes that hypothesis.

Looking at the training loss, we observe a clear downward trend, which suggests the model is improving over time and learning from the data.

<img width="1726" height="544" alt="image" src="https://github.com/user-attachments/assets/95c04cf8-9f11-4c9c-b422-edb7112f462d" />

but the loss is still high

Wall time	    Step	  Value

1757440345	  0	      0.666404963

1757440346	  1	      0.558107376

1757440347	  2	      0.51867193


[Go back to Homepage](../README.md)
